{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"configuration/","title":"Configuration","text":"<p>Configuration for TopoStats is done using a YAML configuration file that is specified on the command line when invoking. If no configuration file is provided this default configuration is loaded automatically and used.</p> <p>The current configuration file is provided in the TopoStats repository at <code>topostats/default_config.yaml</code> but please be aware this may not work with your installed version, particularly if you installed from PyPI.</p>"},{"location":"configuration/#generating-a-configuration","title":"Generating a configuration","text":"<p>You can always generate a configuration file appropriate for the version you have installed (bar v2.0.0 as this option was added afterwards). This writes the default configuration to the specified filename (i.e. it does not have to be called <code>config.yaml</code> it could be called <code>spm-2023-02-20.yaml</code>). There are a few options available (use <code>topostats create-config --help</code> for further details).</p> <pre><code>topostats create-config\n</code></pre>"},{"location":"configuration/#using-a-custom-configuration","title":"Using a custom configuration","text":"<p>If you have generated a configuration file you can modify and edit a configuration it to change the parameters (see fields below). Once these changes have been saved, you can run TopoStats with this configuration file as shown below.</p> <pre><code>topostats process --config my_config.yaml\n</code></pre> <p>On completion a copy of the configuration that was used is written to the output directory so you have a record of the parameters used to generate the results you have. This file can be used in subsequent runs of TopoStats.</p>"},{"location":"configuration/#yaml-structure","title":"YAML Structure","text":"<p>YAML files have key and value pairs, the first word, e.g. <code>base_dir</code> is the key this is followed by a colon to separate it from the value that it takes, by default <code>base_dir</code> takes the value <code>./</code> (which means the current directory) and so the entry in the file is a single line with <code>base_dir: ./</code>. Other data structures are available in YAML files including nested values and lists.</p> <p>A list in YAML consists of a key (e.g. <code>above:</code>) followed by the values in square brackets separated by commas such as <code>above: [ 500, 800 ]</code>. This means the <code>above</code> key is a list of the values <code>500</code> and <code>800</code>. Long lists can be split over separate lines as shown below</p> <pre><code>above:\n  - 100\n  - 200\n  - 300\n  - 400\n</code></pre>"},{"location":"configuration/#fields","title":"Fields","text":"<p>Aside from the comments in YAML file itself the fields are described below.</p> Section Sub-Section Data Type Default Description <code>base_dir</code> string <code>./</code> Directory to recursively search for files within.[^1] <code>output_dir</code> string <code>./output</code> Directory that output should be saved to.[^1] <code>log_level</code> string <code>info</code> Verbosity of logging, options are (in increasing order) <code>warning</code>, <code>error</code>, <code>info</code>, <code>debug</code>. <code>cores</code> integer <code>2</code> Number of cores to run parallel processes on. <code>file_ext</code> string <code>.spm</code> File extensions to search for. <code>loading</code> <code>channel</code> string <code>Height</code> The channel of data to be processed, what this is will depend on the file-format you are processing and the channel you wish to process. <code>filter</code> <code>run</code> boolean <code>true</code> Whether to run the filtering stage, without this other stages won't run so leave as <code>true</code>. <code>threshold_method</code> str <code>std_dev</code> Threshold method for filtering, options are <code>ostu</code>, <code>std_dev</code> or <code>absolute</code>. <code>otsu_threshold_multiplier</code> float <code>1.0</code> Factor by which the derived Otsu Threshold should be scaled. <code>threshold_std_dev</code> dictionary <code>10.0, 1.0</code> A pair of values that scale the standard deviation, after scaling the standard deviation <code>below</code> is subtracted from the image mean to give the below/lower threshold and the <code>above</code> is added to the image mean to give the above/upper threshold. These values should always be positive. <code>threshold_absolute</code> dictionary <code>-1.0, 1.0</code> Below (first) and above (second) absolute threshold for separating data from the image background. <code>gaussian_size</code> float <code>0.5</code> The number of standard deviations to build the Gaussian kernel and thus affects the degree of blurring. See skimage.filters.gaussian and <code>sigma</code> for more information. <code>gaussian_mode</code> string <code>nearest</code> <code>grains</code> <code>run</code> boolean <code>true</code> Whether to run grain finding. Options <code>true</code>, <code>false</code> <code>row_alignment_quantile</code> float <code>0.5</code> Quantile (0.0 to 1.0) to be used to determine the average background for the image. below values may improve flattening of large features. <code>smallest_grain_size_nm2</code> int <code>100</code> The smallest size of grains to be included (in nm^2), anything smaller than this is considered noise and removed. NB must be <code>&gt; 0.0</code>. <code>threshold_method</code> float <code>std_dev</code> Threshold method for grain finding. Options : <code>otsu</code>, <code>std_dev</code>, <code>absolute</code> <code>otsu_threshold_multiplier</code> <code>1.0</code> Factor by which the derived Otsu Threshold should be scaled. <code>threshold_std_dev</code> dictionary <code>10.0, 1.0</code> A pair of values that scale the standard deviation, after scaling the standard deviation <code>below</code> is subtracted from the image mean to give the below/lower threshold and the <code>above</code> is added to the image mean to give the above/upper threshold. These values should always be positive. <code>threshold_absolute</code> dictionary <code>-1.0, 1.0</code> Below (first), above (second) absolute threshold for separating grains from the image background. <code>direction</code> <code>above</code> Defines whether to look for grains above or below thresholds or both. Options: <code>above</code>, <code>below</code>, <code>both</code> <code>smallest_grain_size</code> int <code>50</code> Catch-all value for the minimum size of grains. Measured in nanometres squared. All grains with area below than this value are removed. <code>absolute_area_threshold</code> dictionary <code>[300, 3000], [null, null]</code> Area thresholds for above the image background (first) and below the image background (second), which grain sizes are permitted, measured in nanometres squared. All grains outside this area range are removed. <code>remove_edge_intersecting_grains</code> boolean <code>true</code> Whether to remove grains that intersect the image border. Do not change this unless you know what you are doing. This will ruin any statistics relating to grain size, shape and DNA traces. <code>grainstats</code> <code>run</code> boolean <code>true</code> Whether to calculate grain statistics. Options : <code>true</code>, <code>false</code> <code>cropped_size</code> float <code>40.0</code> Force cropping of grains to this length (in nm) of square cropped images (can take <code>-1</code> for grain-sized box) <code>edge_detection_method</code> str <code>binary_erosion</code> Type of edge detection method to use when determining the edges of grain masks before calculating statistics on them. Options : <code>binary_erosion</code>, <code>canny</code>. <code>dnatracing</code> <code>run</code> boolean <code>true</code> Whether to run DNA Tracing. Options : true, false <code>min_skeleton_size</code> int <code>10</code> The minimum number of pixels a skeleton should be for statistics to be calculated on it. Anything smaller than this is dropped but grain statistics are retained. <code>skeletonisation_method</code> str <code>topostats</code> Skeletonisation method to use, possible options are <code>zhang</code>, <code>lee</code>, <code>thin</code> (from Scikit-image Morphology module) or the original bespoke TopoStas method <code>topostats</code>. <code>spline_step_size</code> float <code>7.0e-9</code> The sampling rate of the spline in metres. This is the frequency at which points are sampled from fitted traces to act as guide points for the splining process using scipy's splprep. <code>spline_linear_smoothing</code> float <code>5.0</code> The amount of smoothing to apply to splines of linear molecule traces. <code>spline_circular_smoothing</code> float <code>0.0</code> The amount of smoothing to apply to splines of circular molecule traces. <code>pad_width</code> int 10 Padding for individual grains when tracing. This is sometimes required if the bounding box around grains is too tight and they touch the edge of the image. <code>cores</code> int 1 Number of cores to use for tracing. NB Currently this is NOT used and should be left commented in the YAML file. <code>plotting</code> <code>run</code> boolean <code>true</code> Whether to run plotting. Options : <code>true</code>, <code>false</code> <code>style</code> str <code>topostats.mplstyle</code> The default loads a custom matplotlibrc param file that comes with TopoStats. Users can specify the path to their own style file as an alternative. <code>save_format</code> string <code>null</code> Format to save images in, <code>null</code> defaults to <code>png</code> see matplotlib.pyplot.savefig <code>savefig_dpi</code> string / float <code>null</code> Dots Per Inch (DPI), if <code>null</code> then the value <code>figure</code> is used, for other values (typically integers) see [#further-customisation] and Matplotlib. Low DPI's improve processing time but can reduce the plotted trace (but not the actual trace) accuracy. <code>pixel_interpolation</code> string <code>null</code> Interpolation method for image plots. Recommended default 'null' prevents banding that occurs in some images. If interpolation is needed, we recommend <code>gaussian</code>. See matplotlib imshow interpolations documentation for details. <code>image_set</code> string <code>all</code> Which images to plot. Options : <code>all</code>, <code>core</code> (flattened image, grain mask overlay and trace overlay only). <code>zrange</code> list <code>[0, 3]</code> Low (first number) and high (second number) height range for core images (can take [null, null]). NB <code>low &lt;= high</code> otherwise you will see a <code>ValueError: minvalue must be less than or equal to maxvalue</code> error. <code>colorbar</code> boolean <code>true</code> Whether to include the colorbar scale in plots. Options <code>true</code>, <code>false</code> <code>axes</code> boolean <code>true</code> Whether to include the axes in the produced plots. <code>num_ticks</code> null / int <code>null</code> Number of ticks to have along the x and y axes. Options : <code>null</code> (auto) or an integer &gt;1 <code>cmap</code> string <code>null</code> Colormap/colourmap to use (defaults to 'nanoscope' if null (defined in <code>topostats/topostats.mplstyle</code>). Other options are 'afmhot', 'viridis' etc., see Matplotlib : Choosing Colormaps. <code>mask_cmap</code> string <code>blu</code> Color used when masking regions. Options <code>blu</code>, <code>jet_r</code> or any valid Matplotlib colour. <code>histogram_log_axis</code> boolean <code>false</code> Whether to plot hisograms using a logarithmic scale or not. Options: <code>true</code>, <code>false</code>. <code>summary_stats</code> <code>run</code> boolean <code>true</code> Whether to generate summary statistical plots of the distribution of different metrics grouped by the image that has been processed. <code>config</code> str <code>null</code> Path to a summary config YAML file that configures/controls how plotting is done. If one is not specified either the command line argument <code>--summary_config</code> value will be used or if that option is not invoked the default <code>topostats/summary_config.yaml</code> will be used."},{"location":"configuration/#summary-configuration","title":"Summary Configuration","text":"<p>Plots summarising the distribution of metrics are generated by default. The behaviour is controlled by a configuration file. The default example can be found in <code>topostats/summary_config.yaml</code>. The fields of this file are described below.</p> Section Sub-Section Data Type Default Description <code>output_dir</code> <code>str</code> <code>./output/</code> Where output plots should be saved to. <code>csv_file</code> <code>str</code> <code>null</code> Where the results file should be loaded when running <code>toposum</code> <code>file_ext</code> <code>str</code> <code>png</code> File type to save images as. <code>pickle_plots</code> <code>bool</code> True Whether to save images to a Python pickle. <code>var_to_label</code> <code>str</code> <code>null</code> Optional YAML file that maps variable names to labels, uses <code>topostats/var_to_label.yaml</code> if null. <code>molecule_id</code> <code>str</code> <code>molecule_number</code> Variable containing the molecule number. <code>image_id</code> <code>str</code> <code>image</code> Variable containing the image identifier. <code>hist</code> <code>bool</code> <code>True</code> Whether to plot a histogram of statistics. <code>bins</code> <code>int</code> <code>20</code> Number of bins to plot in histogram. <code>stat</code> <code>str</code> <code>count</code> What metric to plot on histogram valid values are <code>count</code> (default), <code>frequency</code>, <code>probability</code>, <code>percent</code>, <code>density</code> <code>kde</code> <code>bool</code> <code>True</code> Whether to include a Kernel Density Estimate on histograms. NB if both <code>hist</code> and <code>kde</code> are true they are overlaid. <code>violin</code> <code>bool</code> <code>True</code> Whether to generate Violin Plots. <code>figsize</code> <code>list</code> <code>[16, 9]</code> Figure size (x then y dimensions). <code>alpha</code> <code>float</code> <code>0.5</code> Level of transparency to use when plotting. <code>palette</code> <code>str</code> <code>bright</code> Seaborn color palette. Options <code>colorblind</code>, <code>deep</code>, <code>muted</code>, <code>pastel</code>, <code>bright</code>, <code>dark</code>, <code>Spectral</code>, <code>Set2</code> <code>stats_to_sum</code> <code>list</code> <code>str</code> A list of strings of variables to plot, comment (placing a <code>#</code> at the start of the line) and uncomment as required. Possible values are <code>area</code>, <code>area_cartesian_bbox</code>, <code>aspect_ratio</code>, <code>banding_angle</code>, <code>contour_length</code>, <code>end_to_end_distance</code>, <code>height_max</code>, <code>height_mean</code>, <code>height_median</code>, <code>height_min</code>, <code>radius_max</code>, <code>radius_mean</code>, <code>radius_median</code>, <code>radius_min</code>, <code>smallest_bounding_area</code>, <code>smallest_bounding_length</code>, <code>smallest_bounding_width</code>, <code>volume</code>"},{"location":"configuration/#validation","title":"Validation","text":"<p>Configuration files are validated against a schema to check that the values in the configuration file are within the expected ranges or valid parameters. This helps capture problems early and should provide informative messages as to what needs correcting if there are errors.</p>"},{"location":"configuration/#matplotlib-style","title":"Matplotlib Style","text":"<p>TopoStats generates a number of images of the scans at various steps in the processing. These are plotted using the Python library Matplotlib. A custom <code>matplotlibrc</code> file is included in TopoStats which defines the default parameters for generating images. This covers all aspects of a plot that can be customised, for example we define custom colour maps <code>nanoscope</code> and <code>afmhot</code>. By default the former is configured to be used. Other parameters that are customised are the <code>font.size</code> which affects axis labels and titles.</p> <p>If you wish to modify the look of all images that are output you can generate a copy of the default configuration using <code>topostats create-matplotlibrc</code> command which will write the output to <code>topostats.mplstyle</code> by default (NB there are flags which allow you to specify the location and filename to write to, see <code>topostats create-matplotlibrc --help</code> for further details).</p> <p>You should read and understand this commented file in detail. Once changes have been made you can run TopoStats using this custom file using the following command (substituting <code>my_custom_topostats.mplstyle</code> for whatever you have saved your file as).</p> <pre><code>topostats process --matplotlibrc my_custom_topostats.mplstyle\n</code></pre> <p>NB Plotting with Matplotlib is highly configurable and there are a plethora of options that you may wish to tweak. Before delving into customising <code>matplotlibrc</code> files it is recommended that you develop and build the style of plot you wish to generate using Jupyter Notebooks and then translate them to the configuration file. Detailing all of the possible options is beyond the scope of TopoStats but the Matplotlib documentation is comprehensive and there are some sample Jupyter Notebooks (see <code>notebooks/03-plotting-scans.ipynb</code>) that guide you through the basics.</p>"},{"location":"configuration/#further-customisation","title":"Further customisation","text":"<p>Whilst the overall look of images is controlled in this manner there is one additional file that controls how images are plotted in terms of filenames, titles and image types and whether an image is part of the <code>core</code> subset (flattened image, grain mask overlay and trace overlay) that are always generated or not.</p> <p>This is the <code>topostats/plotting_dictionary.yaml</code> which for each image stage defines whether it is a component of the <code>core</code> subset of images that are always generated, sets the <code>filename</code>, the <code>title</code> on the plot, the <code>image_type</code> (whether it is a binary image), the <code>savefig_dpi</code> which controls the Dots Per Inch (essentially the resolution). Each image has the following structure.</p> <pre><code>z_threshed:\n  title: \"Height Thresholded\"\n  image_type: \"non-binary\"\n  savefig_dpi: 100\n  core_set: true\n</code></pre> <p>Whilst it is possible to edit this file it is not recommended to do so.</p> <p>The following section describes how to override the DPI settings defined in this file and change the global <code>cmap</code> (colormap/colourmap) used in plotting and output format.</p>"},{"location":"configuration/#dpi","title":"DPI","text":"<p>During development it was found that setting high DPI globally for all images had a detrimental impact on processing speeds, slowing down the overall processing time. The solution we have implemented is to use the <code>topostats/plotting_dictionary.yaml</code> file and set the <code>savefig_dpi</code> parameter on a per-image basis.</p> <p>If you wish to change the DPI there are two options, you can change the value for all images by modifying the setting in your a custom configuration by modifying the <code>savefig_dpi</code> from <code>null</code> to your desired value. The example below shows a section of the configuration file you can generate and setting this value to <code>400</code>.</p> <pre><code>plotting:\n  run: true # Options : true, false\n  style: topostats.mplstyle # Options : topostats.mplstyle or path to a matplotlibrc params file\n  savefig_format: null # Options : null (defaults to png) or see https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html\n  savefig_dpi: 400 # Options : null (defaults to format) see https://afm-spm.github.io/TopoStats/main/configuration.html#further-customisation and https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html\n</code></pre> <p>The value in the configuration file (or the default if none is specified) can also be configured at run-time using the <code>--savefig-dpi ###</code> option to the <code>topostats process</code>. This will over-ride both the default or any value specified in a custom configuration you may have set. The following sets this to <code>400</code></p> <pre><code>topostats process --savefig-dpi 400\n</code></pre> <p>NB Changing the DPI in this manner will apply to all images and may significantly reduce processing speed as it takes longer to write images with high DPI to disk.</p> <p>If you wish to have fine grained control over the DPI on a per-image basis when batch processing then your only recourse is to change the values in <code>topostats/plotting_dictionary.yaml</code>. Where this is depends on how you have installed TopoStats, if it is from a clone of the Git repository then it can be found in <code>TopoStats/topostats/plotting_dictionary.yaml</code>. If you have installed from PyPI using <code>pip install topostats</code> then it will be under the virtual environment you have created e.g. <code>~/.virtualenvs/topostats/lib/python3.11/site-packages/topostats/topostats/plotting_dictionary.yaml</code> if you are using plain virtual environments or <code>~/miniconda3/envs/topostats/lib/python3.11/site-packages/topostats/topostats/plotting_dictionary.yaml</code> if you are using Conda environments and chose <code>~/miniconda3</code> as the base directory when installing Conda.</p> <p>If you have installed TopoStats from the cloned Git repository the file will be under <code>TopoStats/topostats/plotting_dictionary.yaml</code>.</p> <p>NB The exact location will be highly specific to your system so the above are just guides as to where to find things.</p>"},{"location":"configuration/#colormap","title":"Colormap","text":"<p>The colormap used to plot images is set globally in <code>topostats/default_config.yaml</code>. TopoStats includes two custom colormaps <code>nanoscope</code> and <code>afmhot</code> but any colormap recognised by Matplotlib can be used (see the Matplotlib Colormap reference for choices).</p> <p>If you want to modify the colormap that is used you have two options. Firstly you can generate a configuration file and modify the field <code>cmap</code> to your choice. The example below shows changing this from <code>null</code> (which defaults to <code>nanoscope</code> as defined in <code>topostats.mplstyle</code>) to <code>rainbow</code>.</p> <pre><code>plotting:\n  ...\n  cmap: rainbow # Colormap/colourmap to use (default is 'nanoscope' which is used if null, other options are 'afmhot', 'viridis' etc.)\n</code></pre> <p>Alternatively it is possible to specify the colormap that is used on the command line using the <code>--cmap</code> option to <code>topostats process</code>. This will over-ride both the default or any value specified in a custom configuration you may have set. The following sets this to <code>rainbow</code>.</p> <pre><code>topostats process --cmap rainbow\n</code></pre>"},{"location":"configuration/#saved-image-format","title":"Saved Image format","text":"<p>Matplotlib, and by extension TopoStats, supports saving images in a range of different formats including <code>png</code> (Portable Network Graphic), <code>svg</code> (Scalable Vector Graphics), <code>pdf</code> (Portable Document Format), and <code>tif</code> (Tag Image File Format). The default is <code>png</code> but, as with both DPI and Colormap, these can be easily changed via a custom configuration file or command line options to change these without having to edit the Matplotlib Style file. If using <code>tif</code> it is worth being aware that although the image will be saved, this will be without metadata since this is not supported for <code>tif</code> files (see the note under <code>metadata</code> of Matplotlib savefig).</p> <p>If you want to modify the output file format that is used you have two options. Firstly you can generate a configuration file and modify the field <code>savefig_format</code> to your choice. The example below shows changing this from <code>null</code> (which defaults to <code>png</code> as defined in <code>topostats.mplstyle</code>) to <code>svg</code>.</p> <pre><code>plotting:\n  ...\n  savefig_format: svg # Options : null (defaults to png) or see https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.savefig.html\n</code></pre> <p>Alternatively it is possible to specify the output image format that is used on the command line using the <code>--savefig-format</code> option to <code>topostats process</code>. This will over-ride both the default or any value specified in a custom configuration you may have set. The following sets this to <code>svg</code>.</p> <pre><code>topostats process --savefig-format svg\n</code></pre> <p>NB Note that these options are not mutually exclusive and can therefore be combined along with any of the other options available to <code>topostats process</code>. The following would use a DPI of <code>400</code>, set the colormap to <code>rainbow</code> and the output format to <code>svg</code> when running Topostats and would over-ride options in any custom configuration file or matplotlib style file.</p> <pre><code>topostats process --savefig-dpi 400 --cmap rainbow --savefig-format svg\n</code></pre> <p>[^1] When writing file paths you can use absolute or relative paths. On Windows systems absolute paths start with the drive letter (e.g. <code>c:/</code>) on Linux and OSX systems they start with <code>/</code>. Relative paths are started either with a <code>./</code> which denotes the current directory or one or more <code>../</code> which means the higher level directory from the current directory. You can always find the current directory you are in using the <code>pwd</code> (<code>p</code>rint <code>w</code>orking <code>d</code>irectory). If your work is in <code>/home/user/path/to/my/data</code> and <code>pwd</code> prints <code>/home/user</code> then the relative path to your data is <code>./path/to/my/data</code>. The <code>cd</code> command is used to <code>c</code>hange <code>d</code>irectory.</p> <pre><code>pwd\n/home/user/\n# Two ways of changing directory using a relative path\ncd ./path/to/my/data\npwd\n/home/user/path/to/my/data\n# Using an absolute path\ncd /home/user/path/to/my/data\npwd\n/home/user/path/to/my/data\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>This document describes how to contribute to the development of this software.</p>"},{"location":"contributing/#contribution-workflow","title":"Contribution Workflow","text":""},{"location":"contributing/#create-an-issue","title":"Create an Issue","text":"<p>Before starting please search for and review the existing issues (both <code>open</code> and <code>closed</code>) and pull requests to see if anyone has reported the bug or requested the feature already or work is in progress. If nothing exists then you should create a new issue using one of the templates provided.</p>"},{"location":"contributing/#cloning-the-repository","title":"Cloning the repository","text":"<p>If you wish to make changes yourself you will have to fork the repository to your own account and then clone that if you are not a member of AFM-SPM Organisation. If you are a member then you can clone the repository and make contributions directly.</p> <pre><code># Member of AFM-SPM Organisation\ngit clone git@github.com:AFM-SPM/TopoStats.git\n# Non-member of AFM-SPM cloning fork\ngit clone git@github.com:&lt;YOUR_GITHUB_USERNAME&gt;/TopoStats.git\n</code></pre>"},{"location":"contributing/#install-additional-dependencies","title":"Install Additional Dependencies","text":"<p>If you are going to contribute you should install the additional dependencies for undertaking such work. There are three groups of additional dependencies, <code>dev</code>, <code>docs</code> and <code>tests</code> and you should install all three using <code>pip</code> as shown below.</p> <pre><code>cd TopoStats\npip install \".[dev,docs,tests]\"\n</code></pre>"},{"location":"contributing/#creating-a-branch","title":"Creating a branch","text":"<p>Typically you will now create a branch to work on the issue you wish to address. It is not compulsory but we try to use a consistent nomenclature for branches that shows who has worked on the branch, the issue it pertains to and a short description of the work. To which end you will see branches with the form <code>&lt;GITHUB_USERNAME&gt;/&lt;GITHUB_ISSUE&gt;-&lt;DESCRIPTION&gt;</code>. Some examples are shown below...</p> Branch User Issue Description <code>ns-rse/259-contributing</code> <code>ns-rse</code> 259 <code>contributing</code> short for the issue subject Add contributing section to documentation. <code>SylviaWhittle/204-nanometre-scaling</code> <code>SylviaWhittle</code> 204 <code>nanometre-scaling</code> short for the issue subject Colour scale in nanometers not pixels. <p>How you create a branch depends on how you use Git, some use the integration provided by their IDE, others dedicated clients such as GitKraken and some may use the command line interface. These instructions use the later but you are of course free to use your chosen method of managing Git and GitHub.</p> <p>In this example we branch from <code>dev</code> and create a new branch called <code>ns-rse/000-fix-an-issue</code>.</p> <pre><code># Ensure you are up-to-date on the main branch\ngit checkout main\ngit pull\n# Create and checkout a branch in one step\ngit checkout -b ns-rse/000-fix-an-issue\n# Create and checkout a branch in two steps\ngit branch dev ns-rse/000-fix-an-issue\ngit checkout ns-rse/000-fix-an-issue\n</code></pre> <p>You can now start working on your issue and making regular commits, but please bear in mind the following section on Coding Standards.</p>"},{"location":"contributing/#coding-standards","title":"Coding Standards","text":"<p>To make the codebase easier to maintain we ask that you follow the guidelines below on coding style, linting, typing, documentation and testing.</p>"},{"location":"contributing/#coding-stylelinting","title":"Coding Style/Linting","text":"<p>Using a consistent coding style has many benefits (see Linting : What is all the fluff about?). For this project we aim to adhere to PEP8 - the style Guide for Python Code and do so using the formatting linters black and ruff. Ruff implements the checks made by Flake8, isort and pydocstyle and has some overlap with both Black and Pylint.</p> <p>We also like to ensure the code passes pylint which helps identify code duplication and reduces some of the code smells that we are all prone to making. A <code>.pylintrc</code> is included in the repository. Currently this isn't strictly applied but it is planned for part of the CI/CD pipeline and so we would be grateful if you could lint your code before making Pull Requests.</p> <p>Many popular IDEs such as VSCode, PyCharm, Spyder and Emacs all have support for integrating these linters into your workflow such that when you save a file the linting/formatting is automatically applied.</p>"},{"location":"contributing/#pre-commit","title":"Pre-commit","text":"<p>pre-commit is a powerful and useful tool that runs hooks on your code prior to making commits. For a more detailed exposition see pre-commit : Protecting your future self.</p> <p>The repository includes <code>pre-commit</code> as a development dependency as well as a <code>.pre-commit-config.yaml</code>. To use these locally install <code>pre-commit</code> in your virtual environment and then install the configuration and all the configured hooks (NB this will download specific virtual environments that <code>pre-commit</code> uses when running hooks so the first time this is run may take a little while).</p> <pre><code>pip install \".[dev]\"\npre-commit install --install-hooks\n</code></pre> <p>Currently there are hooks to remove trailing whitespace, check YAML configuration files and a few other common checks as well as hooks for <code>black</code> and <code>ruff</code>. If these fail then you will not be able to make a commit until they are fixed. The <code>black</code> hook will automatically format failed files so you can simply <code>git add</code> those and try committing straight away. <code>flake8</code> does not correct files automatically so the errors will need manually correcting.</p> <p>If you do not enable and resolve issues reported by <code>pre-commit</code> locally before making a pull request you will find the <code>pre-commit.ci</code> GitHub Action will fail, preventing your Pull Request from being merged. You can shorten the feedback loop and speed up the resolution of errors by enabling <code>pre-commit</code> locally and resolving issues before making your commits.</p>"},{"location":"contributing/#typing","title":"Typing","text":"<p>Whilst Python is a dynamically typed language (that is the type of an object is determined dynamically) the use of Type Hints is strongly encouraged as it makes reading and understanding the code considerably easier for contributors. For more on Type Hints see PEP483 and PEP484</p>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>All classes, methods and functions should have Numpy Docstrings defining their functionality, parameters and return values and pylint will note and report the absence of docstrings by way of the <code>missing-function-docstring</code> condition.</p> <p>Further, when new methods are incorporated into the package that introduce changes to the configuration they should be documented under Parameter Configuration. pre-commit has the markdownlint-cli2 hook enabled to lint all Markdown files and will where possible automatically fix things, but some issues need resolving manually.</p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>New features should have unit-tests written and included under the <code>tests/</code> directory to ensure the functions work as expected. The pytest framework is used for running tests along with a number of plugins (pytest-regtest for regression testing; pytest-mpl for testing generated Matplotlib images).</p>"},{"location":"contributing/#debugging","title":"Debugging","text":"<p>To aid with debugging we include the snoop package. The package is disabled by default, but when you have a class, method or function you wish to debug you should add <code>snoop.install(enabled=True)</code> to the file you wish to debug and use the <code>@snoop</code> decorator around the function/method you wish to debug.</p>"},{"location":"contributing/#configuration","title":"Configuration","text":"<p>As described in Parameter Configuration options are primarily passed to TopoStats via a YAML configuration file. When introducing new features that require configuration options you will have to ensure that the default configuration file (<code>topostats/default.yaml</code>) is updated to include your options.</p> <p>Further the <code>topostats.validation.validate.config()</code> function, which checks a valid configuration file with all necessary fields has been passed when invoking <code>topostats</code> sub-commands, will also need updating to include new options in the Schema against which validation of configuration files is made.</p>"},{"location":"contributing/#ide-configuration","title":"IDE Configuration","text":"<p>Linters such as <code>black</code>, <code>flake8</code> and <code>pylint</code> can be configured to work with your IDE so that say Black and/or formatting is applied on saving a file or the code is analysed with <code>pylint</code> on saving and errors reported. Setting up and configuring IDEs to work in this manner is beyond the scope of this document but some links to articles on how to do so are provided.</p> <ul> <li>Linting Python in Visual Studio Code</li> <li>Code Analysis \u2014 Spyder for <code>pylint</code> for Black see How to use   code formatter Black with Spyder.</li> <li>Code Quality Assistance Tips and Tricks, or How to Make Your Code Look Pretty? |   PyCharm</li> <li>Reformat and rearrange code | PyCharm</li> </ul>"},{"location":"data_dictionary/","title":"Data Dictionary","text":"<p>Output from TopoStats includes two sets of statistics in ASCII text <code>.csv</code> files. The tables below detail the columns of these files, the data types, a description and their units where appropriate.</p>"},{"location":"data_dictionary/#all_statisticscsv","title":"<code>all_statistics.csv</code>","text":"<p>The <code>all_statistics.csv</code> file contains details on each grain that has been detected and traced and has the following fields.</p> <p>The <code>all_statistics.csv</code> file contains details on each grain that has been detected and traced and has the following fields.</p> Column / field / feature Description Type Units <code>image</code> Filename (minus extension) of scan. <code>str</code> N/A <code>threshold</code> Whether grain is <code>above</code> or <code>below</code> a threshold. <code>str</code> N/A <code>molecule_number</code> Number of found grain (starts at <code>0</code>) <code>int</code> N/A <code>centre_x</code> x coordinate of grain centre. <code>float</code> m <code>centre_y</code> y coordinate of grain centre. <code>float</code> m <code>radius_min</code> minimum distance from the centroid to edge of the grain. <code>float</code> m <code>radius_max</code> maximum distance from the centroid to edge of the grain. <code>float</code> m <code>radius_mean</code> mean distance from the centroid to the edge of the grain. <code>float</code> m <code>radius_median</code> median distance from the centroid to the edge of the grain. <code>float</code> m <code>height_min</code> Minimum height of grain. <code>float</code> m <code>height_max</code> Maximum height of grain. <code>float</code> m <code>height_median</code> Median height of grain. <code>float</code> m <code>height_mean</code> Mean height of grain. <code>float</code> m <code>volume</code> Volume of the grain calculated as the number of pixels multiplied by each height and scaled to metres. <code>float</code> m^3 <code>area</code> Area of the grain itself calculated as the number of pixels scaled to metres. <code>float</code> m^2 <code>area_cartesian_bbox</code> Area of the bounding box for the grain along the cartesian axes. (Not the smallest bounding box). <code>float</code> m^2 <code>smallest_bounding_width</code> Width of the smallest bounding box for the grain (not along cartesian axes). <code>float</code> m <code>smallest_bounding_length</code> Length of the smallest bounding box for the grain (not along cartesian axes). <code>float</code> m <code>smallest_bounding_area</code> Area of the smallest bounding box for the grain (not along cartesian axes). <code>float</code> m^2 <code>aspect_ratio</code> Aspect ratio of the grain (length / width), always &gt;= 1. <code>float</code> N/A <code>max_feret</code> Longest length of the grain (see Feret diameter). <code>float</code> m <code>min_feret</code> Shortest width of the grain (see Feret diameter). <code>float</code> m <code>contour_length</code> UNKNOWN <code>float</code> m <code>circular</code> Whether the grain is a circular loop or not. <code>float</code> <code>True</code> / <code>False</code> <code>end_to_end_distance</code> UNKNOWN <code>float</code> m <code>basename</code> Directory in which images was found. <code>str</code> N/A"},{"location":"data_dictionary/#image_statscsv","title":"<code>image_stats.csv</code>","text":"<p>The <code>image_stats.csv</code> summarises the metrics</p> Column / field / feature Description Type Units <code>image</code> Filename of image statistics pertain to. <code>str</code> N/A <code>image_size_x_m</code> Width of image. <code>float</code> m <code>image_size_y_m</code> Height of image. <code>float</code> m <code>image_area_m2</code> Area of image (width x height). <code>float</code> m^2 <code>image_size_x_px</code> Width of image in pixels. <code>int</code> N/A <code>image_size_y_px</code> Height of image in pixels. <code>int</code> N/A <code>image_area_px2</code> Area of image in pixels squared. <code>int</code> N/A <code>grains_number_above</code> Number of grains found above threshold. <code>int</code> N/A <code>grains_per_m2_above</code> Density of grains above upper threshold. <code>int</code> N/A <code>grains_number_below</code> Number of grains found below threshold. <code>int</code> N/A <code>grains_per_m2_below</code> Density of grains below lower threshold. <code>int</code> N/A <code>rms_roughness</code> Route Mean Square Roughness, the square root of the mean squared heights across the surface[^1] <code>float</code> N/A <p>[^1][Surface Roughness](https://www.sciencedirect.com/topics/materials-science/surface-roughness); Surface roughness - Wikipedia</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":"<p>This is a collection of questions (and answers) to problems that arise with using TopoStats software for processing Atomic Force Microscopy images.</p> <p>If you have questions that are not answered here please consider starting a new discussion in the TopoStats Discussion section of the GitHub repository. Developers will endeavour to help you resolve your problem and it may get added to this page.</p>"},{"location":"faq/#general-questions","title":"General Questions","text":""},{"location":"faq/#my-files-image-files-are-on-a-mounted-google-drive-can-i-process-them-there","title":"My files image files are on a mounted Google Drive, can I process them there?","text":"<p>Maybe! We have had mixed success with processing images that are located on Google Drive and mounted on your local computer. If you find you are encountering errors such as <code>FileExistsError</code> (see #201) then please copy your files to a local drive on your computer for processing and then copy the results back to the network drive.</p>"},{"location":"faq/#common-errors","title":"Common Errors","text":"<p>Common errors that are encountered along with explanations are listed below.</p>"},{"location":"glossary/","title":"Glossary","text":""},{"location":"glossary/#a","title":"A","text":""},{"location":"glossary/#alignment","title":"alignment","text":""},{"location":"glossary/#b","title":"B","text":""},{"location":"glossary/#c","title":"C","text":""},{"location":"glossary/#csv","title":"csv","text":"<p>Comma Separated Values (CSV) is an ASCII plain-text file format where columns of data are separated by commas.</p>"},{"location":"glossary/#d","title":"D","text":""},{"location":"glossary/#dna","title":"DNA","text":"<p>Deoxyribonucleic acid (DNA) is a double-helix polymer of four molecules Cytosine, Guanine, Adenine and Thymine. It is the genetic material of the vast majority of organisms (some viruses use Ribonucleic Acid (RNA) as their genetic material).</p>"},{"location":"glossary/#e","title":"E","text":""},{"location":"glossary/#f","title":"F","text":""},{"location":"glossary/#flattening","title":"flattening","text":"<p>The process of removing tilt from an image.</p>"},{"location":"glossary/#g","title":"G","text":""},{"location":"glossary/#git","title":"Git","text":"<p>Git is a free, open source version control system for managing software projects and development.</p>"},{"location":"glossary/#github","title":"GitHub","text":"<p>GitHub is a website for sharing and collaboratively working on software that is version controlled using Git.</p>"},{"location":"glossary/#grains","title":"grains","text":"<p>The name given to DNA/RNA/protein structures observed in scans.</p>"},{"location":"glossary/#h","title":"H","text":""},{"location":"glossary/#i","title":"I","text":""},{"location":"glossary/#j","title":"J","text":""},{"location":"glossary/#k","title":"K","text":""},{"location":"glossary/#l","title":"L","text":""},{"location":"glossary/#m","title":"M","text":""},{"location":"glossary/#n","title":"N","text":""},{"location":"glossary/#o","title":"O","text":""},{"location":"glossary/#p","title":"P","text":""},{"location":"glossary/#python","title":"Python","text":"<p>Python is the high-level interpreted programming language in which TopoStats is written.</p>"},{"location":"glossary/#q","title":"Q","text":""},{"location":"glossary/#r","title":"R","text":""},{"location":"glossary/#s","title":"S","text":""},{"location":"glossary/#scars","title":"scars","text":"<p>Artefacts seen in some scans that can be removed during processing. Typically they appear as horizontal high bands. These are removed and the missing values interpolated.</p>"},{"location":"glossary/#skeleton","title":"skeleton","text":"<p>The single-pixel width outline of a molecule after a grain has undergone tracing.</p>"},{"location":"glossary/#t","title":"T","text":""},{"location":"glossary/#tilt","title":"tilt","text":""},{"location":"glossary/#tracing","title":"tracing","text":"<p>The processing step where by a grain is reduced to a single pixel or skeleton. Typically a number of statistics on the shape, length and curvature are calculated after molecules have been traced.</p>"},{"location":"glossary/#u","title":"U","text":""},{"location":"glossary/#v","title":"V","text":""},{"location":"glossary/#w","title":"W","text":""},{"location":"glossary/#x","title":"X","text":""},{"location":"glossary/#y","title":"Y","text":""},{"location":"glossary/#z","title":"Z","text":""},{"location":"installation/","title":"Installation","text":"<p>NB - If you have trouble installing TopoStats please do checkout the discussion for possible solutions. If your problem isn't covered then please do not hesitate to ask a question.</p> <p>TopoStats is a Python package designed to run at the command line. If you are using Microsoft Windows you should use Powershell. You may have Python installed on your system but should use a Python Virtual Environment such as Miniconda and install and use TopoStats under the Virtual Environment. The versions of Python supported are Python &gt;=3.8 and so when creating your virtual environment you should specify this <code>3.8</code> as the minimum.</p>"},{"location":"installation/#setting-up-conda","title":"Setting up Conda","text":"<p>Once you have downloaded and installed Miniconda you can create a virtual environment for installing TopoStats for installing and running TopoStats. We will call this environment <code>topostats</code> (specified with the <code>--name topostats</code> option) and use Python 3.10 (the option <code>python=3.10</code>). After creating it we can, as per the instructions printed out, activate the environment.</p> <pre><code>conda create --name topostats python=3.10\nconda activate topostats\n</code></pre> <p>You are now ready to install TopoStats.</p> <p>NB If you are using an Apple M1 Macbook then you need to install Anaconda &gt;= 2022.05.</p>"},{"location":"installation/#installing-topostats","title":"Installing TopoStats","text":"<p>There are two options for installing TopoStats depending on your usage</p> <ol> <li>Python Package Index - appropriate if you are just using TopoStats and don't need to dig into    the code.</li> <li>Cloning the GitHub Repository - if you want to look at the code, contribute to it, debug errors or perhaps test a new    feature before a release.</li> </ol>"},{"location":"installation/#pypi-installation","title":"PyPI Installation","text":"<p>After activating your <code>topostats</code> Conda environment you can install TopoStats from PyPI using the following command.</p> <pre><code>pip install topostats\n</code></pre> <p>This will install TopoStats under your virtual environment and the command <code>topostats</code> will be available at the command line. It has a number of sub-commands which can be displayed by invoking it without any options. You can upgrade <code>topostats</code> by using the <code>--upgrade</code> flag...</p> <pre><code>pip install --upgrade topostats\n</code></pre> <p>You can always install a specific version from PyPI</p> <pre><code>pip install topostats==2.0.0\n</code></pre> <p>For more information on using <code>pip</code> to install and manage packages please refer to the pip documentation.</p>"},{"location":"installation/#installing-from-github","title":"Installing from GitHub","text":"<p>You may wish to consider cloning and installing TopoStats from GitHub if...</p> <ul> <li>You wish to try out new features that have been developed since the last release (if you find problems please create   an issue).</li> <li>If you have found an issue in a released version and want to see if it has been fixed in the unreleased version.</li> <li>If you wish to develop and extend TopoStats with new features yourself.</li> </ul> <p>There are two options to install from GitHub, which you use will depend on what you want to do.</p> <ol> <li>Using PyPI to install directly.</li> <li>Clone the repository and install from there.</li> </ol> <p>If all you want to do is use the development version of TopoStats then you can use option 1. If you wish to change the underlying code you should use option 2.</p>"},{"location":"installation/#installing-from-github-using-pypi","title":"Installing from GitHub using PyPI","text":"<p><code>pip</code> supports installing packages from GitHub. To install the <code>main</code> branch of TopoStats use the following in your Virtual Environment.</p> <pre><code>pip install git+https://github.com/AFM-SPM/TopoStats.git@main\n</code></pre> <p>You can install any branch on GitHub by modifying the last argument (<code>@main</code>) to the branch you wish to install, e.g. <code>@another_branch</code> would install the <code>another_branch</code> (if it existed).</p>"},{"location":"installation/#cloning-the-repository-and-installing","title":"Cloning the Repository and installing","text":"<p>If you do not have Git already installed please see Git. If you intend to contribute to the development of TopoStats please read through the contributing section.</p> <p>If you are familiar with the command line then you can clone and install TopoStats with the following after activating your virtual environment. By installing in editable mode (with the <code>-e</code> flag) switching branches will make the branch available.</p> <pre><code>cd ~/where/to/clone\ngit clone git@github.com:AFM-SPM/TopoStats.git\ncd TopoStats\npip install -e .\n</code></pre> <p>If you plan to contribute to development by adding features or address an existing issue please refer to the contributing section and pay particular attention to the section about installing additional dependencies.</p> <p>We include notebooks which show how to use different aspects of TopoStats. If you wish to try these out the Jupyter Noteooks then you can install the dependencies that are required from the cloned TopoStats repository using...</p> <pre><code>pip install \".[notebooks]\"\n</code></pre>"},{"location":"installation/#cloning-using-gitkraken","title":"Cloning Using GitKraken","text":"<p>If you are using GitKraken you can clone the repository by selecting \"Clone\" and then \"GitHub.com\" and typing <code>TopoStats</code> into the box next to \"Repository to Clone\" and you should be presented with the option of selecting \"TopoStats\" from the AFM-SPM organisation. Once cloned follow the above instructions to install with <code>pip</code> under your virtual environment.</p>"},{"location":"installation/#tests","title":"Tests","text":"<p>One of the major changes in the refactoring is the introduction of unit tests. These require certain packages to be installed which are not installed to your virtual environment by setuptools in the above steps. If you are intending to modify or contribute to the development of TopoStats or make changes to the code base you will likely want to be able to run the tests. Install the necessary dependencies to do so with...</p> <pre><code>cd TopoStats\ngit checkout dev\npip install \".[tests]\"\npytest\n</code></pre>"},{"location":"installation/#git","title":"Git","text":"<p>Git is a version control system for managing software development and is required to be installed on your computer in order to clone the TopoStats repository. Instructions on installing Git can be found at Git Guides - install git.</p> <p>A nice Graphical User Interface for working with Git is GitKraken which includes everything you need.</p>"},{"location":"introduction/","title":"Introduction","text":"<p>TopoStats is a Python package that aims to simplify batch processing Atomic Force Microscopy (AFM) images.</p> <p>Input directories are recursively searched for files of a given type. Each image is then loaded and processed. Multiple images can be processed in parallel.</p> <p>Once an image has been loaded the specified channel of data extracted along with the pixel to nanometre scaling. This data is then aligned and the tilt is removed. Configurable thresholds are then used to generate masks and a second round of tilt removal and row alignment is performed.</p> <p>Molecules/regions of interest known as Grains are then detected based on user specified thresholds and the detected regions are labelled and have preliminary statistics calculated. The labelled regions of each grain then have individual statistics calculated capturing the height, volume, radius and the location of the centroid.</p> <p>Optionally DNA Tracing is then performed, which traces the backbone of the DNA molecules to calculate further statistics such as whether grains are linear or circular, their contour length and end-to-end distances etc.</p> <p>The resulting statistics are written to a CSV file and optionally plots are then generated from various stages of the processing as well as cropped images of each grain. The amount of images produced is also configurable.</p> <p>An schematic overview of the classes and methods that are run in processing files can be found in the workflows page along with more detailed information on installation, usage, configuration and contributing.</p> <p>If you have questions, please post them on the discussion, if you think you've encountered a bug whilst running the code or suggestions for improvements please create an issue in the GitHub project page.</p>"},{"location":"notebooks/","title":"Notebooks","text":"<p>A series of Jupyter Notebooks are provided that demonstrate how to use the TopoStats package in a more interactive manner, calling individual steps. This is useful as it allows the user to explore interactively and with rapid feedback the parameters that may need adjusting in order to process a batch of scans. The notebooks can be found in the <code>notebook/</code> directory after cloning the GitHub repository.</p> Notebook Description <code>00-Walkthrough-minicircle.ipynb</code> Step-by-step walkthrough of processing <code>minicircle.spm</code> from the <code>tests/resources/</code> directory. <code>01-Walthrhgouh-interactive.ipynb</code> Work in Progress As above but uploading a single scan. Will be deployed in Google Colab/Binder for interactive use. <code>02-Summary-statistics-and-plots.ipynb</code> Plotting statistics interactively. <code>03-Plotting-scans.ipynb</code> Plotting NumPy arrays of scans from different stages of processing."},{"location":"notebooks/#installation","title":"Installation","text":"<p>To be able to run the Notebooks you need some additional Python packages installed. You will have to clone the repository from GitHub (see installation) and then install the Notebook dependencies with the following commands under your Virtual Environment (e.g. Conda)...</p> <pre><code>cd TopoStats\npip install \".[notebooks]\"\n</code></pre>"},{"location":"notebooks/#running-notebooks","title":"Running Notebooks","text":"<p>Start a Jupyter server under the Virtual Environment you have installed the dependencies from and a web-browser page will open from which you can choose which notebook to launch.</p> <pre><code>cd TopoStats/notebooks\njupyter notebook\n</code></pre> <p>For more on Jupyter Notebooks please refer to the official documentation.</p>"},{"location":"related_software/","title":"Related Software","text":"<p>TopoStats is one of many pieces of software available for working with Atomic Force Microscopy data, other packages are detailed here. If you know of another package please consider making a pull request to add it to the list.</p>"},{"location":"related_software/#python","title":"Python","text":"<ul> <li>afmformats reading common AFM file formats.</li> <li>gwyfile a pure Python interface to reading and writing Gwyddion files.</li> <li>magni compressive sampling and reconstruction of Atomic Force Microscopy images.</li> <li>nanite loading, fitting and rating AFM force-distance data.</li> <li>nanoforce import and analyse AFM force curves produced using Nanoscope 5 &amp; 6   and Nanosurf <code>.nid</code> files.</li> <li>nanoscope read data files collected using Bruker, Veeco, and Digital   Instruments Atomic Force Microscopes (AFMs) using Nanoscope v5.12 - v10.00 acquisition software</li> <li>NSFOpen Read data and parameters from Nanosurf NID files.</li> <li>pycroscopy Python Package for scientific analysis of nanoscience   data.</li> <li>pySPM read, handle and plot Scanning Probme Microscopy (SPM) images and ToF-SIMS data.</li> </ul>"},{"location":"related_software/#c","title":"C++","text":"<ul> <li>libasd library for reading asd files, includes Python 3 bindings.</li> </ul>"},{"location":"related_software/#other","title":"Other","text":"<ul> <li>gwyddion a modular program for Scanning Probe Microscopy (SPM) data visualisation and analysis.</li> </ul>"},{"location":"usage/","title":"Usage","text":"<p>After having installed TopoStats you are ready to run it. For convenience TopoStats provides a command line interface <code>topostats</code> that will load a default configuration file and process all images with reasonable default configuration options.</p> <p>However, because the location of your image files can not be known in advance you must make a copy of the default configuration and modify it to work with your files. This guide will hopefully take you through the process of running TopoStats and customising the configuration file with which it is run. If you encounter any problems please ask questions in the Discussions. If you think you have encountered a bug or have a feature suggestion please create an Issue.</p>"},{"location":"usage/#organising-scans","title":"Organising Scans","text":"<p>You should place all files you wish to batch process in a single directory. They can be nested in separate folders as TopoStats will scan for all images within this directory but currently it will only process one scan type at a time (i.e. <code>.spm</code> or <code>.jpk</code> or <code>.asd</code>). This may change in the future.</p>"},{"location":"usage/#command-line-navigation","title":"Command Line Navigation","text":"<p>TopoStats currently runs as a command-line programme. To use it you will have to use a \"prompt\" or \"terminal\" (they're essentially the same thing). What you use will depend on your operating system, but the following are some simple commands on navigation. If you use Windows then for consistency it is recommended to install and use PowerShell.</p> <p>At the command line you use <code>cd</code> to <code>c</code>hange <code>d</code>irectory to the location of your files. For example if your scans are on the C-drive in <code>C:\\User\\me\\work\\spm\\2022-12-08\\scans</code> then you would</p> <pre><code>cd c:/User/me/work/spm/2022-12-08/scans\n</code></pre> <p>If you are on a Linux or OSX system then paths are not prefixed with letters and your files may be saved to <code>/home/me/work/spm/2022-12-08/scans</code>. To change directory there you would...</p> <pre><code>cd /home/me/work/spm/2022-12-08/scans\n</code></pre> <p>NB - Always use a forward-slash (<code>/</code>) when typing directory paths. Windows will display back-slash (<code>\\</code>) but understands forward-slash. Under Linux and OSX they mean different things and so you should always use forward-slash (<code>/</code>).</p> <p>You can always find out what location you are at in the command line using the <code>pwd</code> command (<code>p</code>rint <code>w</code>orking <code>d</code>irectory) and it will print out the directory you are currently at.</p> <pre><code>pwd\n/home/me/work/spm/2022-12-08/scans\n</code></pre> <p>To navigate up one directory level use <code>cd ..</code>. These can be chained together and directories separated with <code>/</code>.</p> <pre><code># Move up a single directory level\ncd ..\npwd\n/home/me/work/spm/2022-12-08\n# Move up another two directory levels\ncd ../../\npwd\n/home/me/\n</code></pre> <p>You can list the files in a directory using the <code>ls</code> command.</p> <pre><code>ls\nsample_image_scan_2022-12-08-1204.spm\n</code></pre> <p>To learn more about the command line see the Introduction to the Command Line for Genomics.</p>"},{"location":"usage/#running-topostats","title":"Running TopoStats","text":"<p>The default location that TopoStats looks for scans is the directory from which it is invoked. Once you start your shell/terminal you will therefore need to do two things.</p> <ol> <li>Navigate to the location of the scans you wish to process using <code>cd /path/to/where/scans/are/located</code>.</li> <li>Activate the virtual environment under which you installed TopoStats (refer to installed if unsure).</li> </ol> <p>You can now run topostats by invoking <code>topostats process</code> and you should start to see some output similar to that below.</p> <pre><code>cd /path/to/where/scans/are/located\ntopostats process\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Configuration is valid.\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Plotting configuration is valid.\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Configuration file loaded from      : None\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Scanning for images in              : /home/neil/work/projects/topostats/TopoStats\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Output directory                    : output\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Looking for images with extension   : .spm\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Images with extension .spm in /home/neil/work/projects/topostats/TopoStats : 32\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Thresholding method (Filtering)     : std_dev\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Thresholding method (Grains)        : std_dev\n...\n</code></pre> <p>On a successful completion you should see a message similar to the following which indicates various aspects of the run along with information about how to give feedback, report bugs and cite the software.</p> <pre><code>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ COMPLETE ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n  Base Directory              : /home/neil/work/projects/topostats/TopoStats\n  File Extension              : .spm\n  Files Found                 : 1\n  Successfully Processed      : 1 (100.0%)\n  Configuration               : output/config.yaml\n  All statistics              : output/all_statistics.csv\n  Distribution Plots          : output/summary_distributions\n\n  Email                       : topostats@sheffield.ac.uk\n  Documentation               : https://afm-spm.github.io/topostats/\n  Source Code                 : https://github.com/AFM-SPM/TopoStats/\n  Bug Reports/Feature Request : https://github.com/AFM-SPM/TopoStats/issues/new/choose\n  Citation File Format        : https://github.com/AFM-SPM/TopoStats/blob/main/CITATION.cff\n\n  If you encounter bugs/issues or have feature requests please report them at the above URL\n  or email us.\n\n  If you have found TopoStats useful please consider citing it. A Citation File Format is\n  linked above and available from the Source Code page.\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre> <p>The command <code>topostats process</code> has a number of additional flags for passing different options. These can be viewed using the <code>-h</code> or <code>--help</code> flag.</p> <pre><code> \u2771 topostats process --help\nusage: topostats process [-h] [-c CONFIG_FILE] [-s SUMMARY_CONFIG] [--matplotlibrc MATPLOTLIBRC] [-b BASE_DIR] [-j CORES] [-l LOG_LEVEL] [-f FILE_EXT] [--channel CHANNEL] [-o OUTPUT_DIR] [--save-plots SAVE_PLOTS] [-m MASK] [-w WARNINGS]\n\nProcess AFM images. Additional arguments over-ride those in the configuration file.\n\noptions:\n  -h, --help            show this help message and exit\n  -c CONFIG_FILE, --config-file CONFIG_FILE\n                        Path to a YAML configuration file.\n  -s SUMMARY_CONFIG, --summary-config SUMMARY_CONFIG\n                        Path to a YAML configuration file for summary plots and statistics.\n  --matplotlibrc MATPLOTLIBRC\n                        Path to a matplotlibrc file.\n  -b BASE_DIR, --base-dir BASE_DIR\n                        Base directory to scan for images.\n  -j CORES, --cores CORES\n                        Number of CPU cores to use when processing.\n  -l LOG_LEVEL, --log-level LOG_LEVEL\n                        Logging level to use, default is 'info' for verbose output use 'debug'.\n  -f FILE_EXT, --file-ext FILE_EXT\n                        File extension to scan for.\n  --channel CHANNEL     Channel to extract.\n  -o OUTPUT_DIR, --output-dir OUTPUT_DIR\n                        Output directory to write results to.\n  --save-plots SAVE_PLOTS\n                        Whether to save plots.\n  -m MASK, --mask MASK  Mask the image.\n  -w WARNINGS, --warnings WARNINGS\n                        Whether to ignore warnings.\n</code></pre>"},{"location":"usage/#reducing-output","title":"Reducing Output","text":"<p>If you find the output too verbose or of no use you can reduce it by setting the <code>log_level</code> to either <code>error</code> or <code>warning</code>. This can be done either in the configuration file (see Configuration below) or using the <code>-l</code>/<code>--log-level</code> flag for example <code>topostats process --log_level warning</code>.</p>"},{"location":"usage/#configuring-topostats","title":"Configuring TopoStats","text":"<p>Configuration of TopoStats is done through a YAML file and a full description of the fields used can be found under the configuration section.</p> <p>Here we will go through generating a configuration file to edit and some of the common changes that you are likely to want to make to the default configuration and how to make them.</p>"},{"location":"usage/#generating-configuration-file","title":"Generating Configuration File","text":"<p>TopoStats will use some reasonable default parameters by default, but typically you will want to customise the parameters that are used. This is achieved using a configuration file. This is a YAML file that contains parameters for different settings. For convenience you can generate a sample configuration file in your current working directory using the <code>topostats create-config</code> sub-command. It takes a single argument, the name of the file to save the configuration to (e.g. <code>config.yaml</code> or <code>settings.yaml</code>), and it will write the current default configuration to that file.</p> <pre><code>topostats create-config --filename my_config.yaml\nls -l\nmy_config.yaml\nsample_image_scan_2022-12-08-1204.spm\n</code></pre> <p>You can now edit and/or rename the <code>my_config.yaml</code>. It can be called anything you want, e.g. <code>todays_first_run_configuration.yaml</code> is a valid name.</p>"},{"location":"usage/#editing-configyaml","title":"Editing <code>config.yaml</code>","text":"<p>IMPORTANT This file is an ASCII text file and you should use NotePad (Windows), TextEdit (OSX) or Nano/Emacs/Vim (GNU/Linux) or any other text editor. Do not use Microsoft Word or any other Word Processor to edit this file.</p> <p>You can now start customising the configuration you are going to run TopoStats with. All fields have defaults but the ones you may want to change are....</p> <ul> <li><code>base_dir</code> (default: <code>./</code>) the directory in which to search for scans. By default this is <code>./</code> which represents the   directory from which <code>topostats process</code> is called and it is good practice to have one configuration file per batch of   scans that are being processed.</li> <li><code>output_dir</code> (default: <code>output</code>) the location where the output is saved, by default this is the directory <code>output</code>   which will be created if it doesn't exist. If you wish for the output to be somewhere else specify it here. If you   want <code>Processed</code> directories to sit within the directories that images are found then simply set the <code>output_dir</code> to   the same value as <code>base_dir</code>.</li> <li><code>log_level</code> (default: <code>info</code>) the verbosity of output to the console and log file, the options in order of verbosity   are <code>debug</code> &gt; <code>info</code> &gt; <code>warning</code> &gt; <code>error</code>. If you want less output set to <code>warning</code> or <code>error</code>. If you encounter   errors please set to <code>debug</code> and run again and include the log in your bug   report.</li> <li><code>cores</code> (default: <code>2</code>) the number of parallel processes to run processing of all found images. Set this to a maximum   of one less than the number of cores on your computers CPU. If unsure leave as is, but chances are you can increase   this to at least <code>4</code> quite safely.</li> <li><code>file_ext</code> (default: <code>.spm</code>) the file extension of scans to search for within the current directory. The default is   <code>.spm</code> but other file format support is in the pipeline.</li> <li><code>plotting</code> : <code>image_set</code> (default <code>core</code>) specifies which steps of the processing to plot images of. The value <code>all</code>   gets images for all stages, <code>core</code> saves only a subset of images.</li> </ul> <p>Most of the other configuration options can be left on their default values for now. Once you have made any changes save the file and return to your terminal.</p>"},{"location":"usage/#running-topostats-with-my_configyaml","title":"Running TopoStats with <code>my_config.yaml</code>","text":"<p>To use your new configuration file you need to inform <code>topostats process</code> to use that file rather than the defaults, this is done using the <code>--config config.yaml</code> file.</p> <p>NB this assumes that you are in the same directory as your scans where you have saved the <code>my_config.yaml</code> file that you edited. That doesn't have to be the case but it makes life easier for if you are not familiar with absolute and relative paths.</p> <pre><code>topostats process --config my_config.yaml\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Configuration is valid.\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Plotting configuration is valid.\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Configuration file loaded from      : None\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Scanning for images in              : /home/neil/work/projects/topostats/TopoStats\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Output directory                    : output\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Looking for images with extension   : .spm\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Images with extension .spm in /home/neil/work/projects/topostats/TopoStats : 1\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Thresholding method (Filtering)     : std_dev\n[Tue, 15 Nov 2022 12:39:48] [INFO    ] [topostats] Thresholding method (Grains)        : std_dev\n...\n</code></pre> <p>On successful completion you should see the same message noted above.</p>"},{"location":"usage/#output","title":"Output","text":"<p>The output from running TopoStats is saved in the location defined in the configuration file by <code>output_dir</code>. The default is the directory <code>output</code> within the directory from which <code>topostats process</code>. This may differ if you have used your own customised configuration file (specifically if you have modified the <code>output_dir:</code> option).</p> <p>At the top level of the output directory are two files <code>config.yaml</code> and <code>all_statistics.csv</code></p> <ul> <li><code>config.yaml</code> : a copy of the configuration used to process the images.</li> <li><code>all_statistics.csv</code> : a Comma Separated Variable ASCII plain-text file of the grain and DNA tracing statistics.</li> </ul> <p>The remaining directories of results is contingent on the structure of files within the <code>base_dir</code> that is specified in the configuration. If all files are in the top-level directory (i.e. no nesting) then you will have just a <code>Processed</code> directory. If there is a nested structure then there will be a <code>Processed</code> directory in each folder that an image with the specified <code>file_ext</code> has been found. This is perhaps best illustrated by way of example.</p> <p>If you have the following three <code>.spm</code> files within your current directory, one at the top level, one under <code>level1</code> and one under <code>level1/a</code>...</p> <pre><code>[4.0K Nov 15 13:55]  .\n|-- [4.0K Nov 15 13:54]  ./level1\n|   |-- [4.0K Nov 15 13:54]  ./level1/a\n|   |-- [ 32M Nov 15 13:54]  ./level1/a/minicircle.spm\n|   |-- [ 32M Nov 15 13:54]  ./level1/minicircle.spm\n|-- [ 32M Nov 15 13:54]  ./minicircle.spm\n</code></pre> <p>...then under <code>output</code> (the default for<code>output_dir</code>) you will see the following directory structure.</p> <pre><code>[4.0K Nov 15 14:06]  output\n|-- [ 381 Nov 15 14:06]  output/all_statistics.csv\n|-- [7.4K Nov 15 14:06]  output/config.yaml\n|-- [4.0K Nov 15 14:06]  output/level1\n|   |-- [4.0K Nov 15 14:06]  output/level1/a\n|   |   |-- [4.0K Nov 15 14:06]  output/level1/a/Processed\n|   |-- [4.0K Nov 15 14:06]  output/level1/Processed\n|-- [4.0K Nov 15 14:06]  output/Processed\n</code></pre> <p>...where there is one <code>Processed</code> directory at the sub-directory level that each image was found.</p> <p>NB If you want <code>Processed</code> directories to sit within the directories that images are found then simply set the <code>output_dir</code> to the same value as <code>base_dir</code>.</p> <p>Within each <code>Processed</code> directory is a directory for each file found with the specified <code>file_ext</code> and within these are the resulting images from processing scans. If the <code>plotting</code> : <code>image_set</code> is <code>core</code> then there is a single image for each. If this option is <code>all</code> then there is also a sub-directory for each image found within which there are the directories <code>filters</code>, <code>grains/below</code> and <code>grains/above</code> which contain additional images from the processing stages and an accompanying histogram for each image showing the distribution of pixel heights for that image.</p>"},{"location":"usage/#summary-plots","title":"Summary Plots","text":"<p>By default TopoStats will take the data that has been summarised across all files and generate a series of plots, histograms with Kernel Density Estimates (KDE) overlaid and Violin plots. The default location of these if no custom configuration file is used is <code>output/summary_distributions</code>. If you have used a custom configuration file it will be the sub-directory <code>summary_distributions</code> nested under the directory specified for the <code>output</code>, e.g. if you used the current directory as output you will have a <code>summary_distributions</code> directory present.</p> <p>Sometimes you may have a <code>all_statistics.csv</code> from a run and wish to plot distributions of additional statistics that were not already plotted. This can be achieved using the command line programme <code>toposum</code> which is included.</p> <p>NB Because of the inherent complexity of plots this script is, by design, limited in the scope to which plots can be configured. It uses the plotting library Seaborn (which is built on top of Matplotlib) to produce basic plots, which are not intended for publication. If you want to tweak or customise plots it is recommended to load <code>all_statistics.csv</code> into a Jupyter Notebook and generate the plots you want there. A sample notebook is included to show how to do this.</p>"},{"location":"usage/#configuring-summary-plots","title":"Configuring Summary Plots","text":"<p>Configuration of summary plots is also via a YAML configuration file a description of the fields can be found under configuration page. You can generate a sample configuration by invoking the <code>--create-config-file</code> option to <code>toposum</code></p> <pre><code>toposum --create-config-file custom_summary_config.yaml\n</code></pre> <p>The file <code>custom_summary_config.yaml</code> can then be edited to change what plots are generated, where they are saved to and so forth. Typically you will only want to adjust a few settings such as toggling the types of plots (<code>hist</code>, <code>kde</code> and <code>violin</code>), the number of <code>bins</code> in a histogram or the statistic to plot in histograms (<code>count</code>, <code>frequency</code> etc.). You can change the <code>palette</code> that is used by Seaborn and crucially toggle which statistics are summarised by commenting and uncommenting the statistic names under <code>stats_to_sum</code>.</p>"},{"location":"usage/#labels","title":"Labels","text":"<p>Labels for the plots are generated from the file <code>topostats/var_to_label.yaml</code> which provides a dictionary that maps the variable name as the dictionary <code>key</code> to its description stored in the dictionary <code>value</code>. If you wish to customise these you can do so and pass it to <code>toposum</code> using the <code>--plotting_dictionary</code> which takes as an argument the path to the file you have created.</p>"},{"location":"usage/#pickles","title":"Pickles","text":"<p>The option <code>pickle_plots: True</code> will save to the specified <code>output_dir</code> the file <code>distribution_plots.pkl</code> which is a binary format that saves the plots that have been generated and saved in nested dictionaries so that they can be loaded again. The Notebook <code>notebooks/02-Summary-statistics-and-plots.ipynb</code> shows how to load these and make simple modifications to the the plots.</p>"},{"location":"workflow/","title":"Workflow","text":"<p>This section gives a broad overview of the steps taken in processing images.</p>"},{"location":"workflow/#topotracing-processing-a-single-spm-file","title":"Topotracing : Processing a single <code>.spm</code> file","text":"<p>Topotracing loads images from <code>.spm</code> files and extracts the specified channel, performing various filtering stages (<code>Filters()</code> class) before finding grains (<code>Grains()</code> class) and then calculating statistics for each grain (<code>GrainStats()</code> class). The Gaussian filtered image and labelling of grains is then passed onto DNA Tracing.</p> <pre><code>%%{init: {'theme': 'base',\n         }\n}%%\ngraph TD;\n\n  subgraph Background Flattening\n  A1([Load YAML Configuration]) --&gt; A2([Load SPM])\n  A2 --&gt; A3([Extract channel from SPM])\n  A3 --&gt; A4([Initial Align])\n  A4 --&gt; A5([Initial Tilt Removal])\n  A5 --&gt; A6([Thresholding Otsu])\n  A6 --&gt; A7([Mask Generation])\n  A7 --&gt; A8([Masked Align])\n  A8 --&gt; A9([Masked Tilt Removal])\n  A9 --&gt; A10([Background Zeroing])\n  end\n  subgraph Grain Finding\n  A10 --&gt; B1([Lower Thresholding])\n  B1 --&gt; B2([Gaussian Filtering])\n  B2 --&gt; B3([Tidy Edges])\n  B3 --&gt; B4([Preliminary Statistics])\n  B4 --&gt; B5([Size Thresholding])\n  B5 --&gt; B6([Label Regions])\n  end\n  subgraph Grain Statistics\n  B6 --&gt; C2([Calculate Points])\n  C2 --&gt; C8([Height &amp; Volume Statistics])\n  C2 --&gt; C3([Calculate Edges])\n  C2 --&gt; C4([Calculate Centroid])\n  C3 --&gt; C5([Calculate Radius Statistics])\n  C3 --&gt; C6([Convex Hull / Graham Scan])\n  C6 --&gt; C7([Minimum Bounding Box Statistics])\n  end\n  subgraph DNA Tracing\n  B2 --&gt; D1([More Analysis])\n  B5 --&gt; D1\n  end\n  style A1 fill:#648FFF,stroke:#000000\n  style A2 fill:#648FFF,stroke:#000000\n  style A3 fill:#648FFF,stroke:#000000\n  style A4 fill:#648FFF,stroke:#000000\n  style A5 fill:#648FFF,stroke:#000000\n  style A6 fill:#648FFF,stroke:#000000\n  style A7 fill:#648FFF,stroke:#000000\n  style A8 fill:#648FFF,stroke:#000000\n  style A9 fill:#648FFF,stroke:#000000\n  style A10 fill:#648FFF,stroke:#000000\n  style B1 fill:#DC267F,stroke:#000000\n  style B2 fill:#DC267F,stroke:#000000\n  style B3 fill:#DC267F,stroke:#000000\n  style B4 fill:#DC267F,stroke:#000000\n  style B5 fill:#DC267F,stroke:#000000\n  style B6 fill:#DC267F,stroke:#000000\n  style C2 fill:#FE6100,stroke:#000000\n  style C3 fill:#FE6100,stroke:#000000\n  style C4 fill:#FE6100,stroke:#000000\n  style C5 fill:#FE6100,stroke:#000000\n  style C6 fill:#FE6100,stroke:#000000\n  style C7 fill:#FE6100,stroke:#000000\n  style C8 fill:#FE6100,stroke:#000000\n  style D1 fill:#785EF0,stroke:#000000\n</code></pre>"},{"location":"workflow/#dna-tracing-processing-a-single-grain","title":"DNA Tracing : Processing a single grain","text":"<pre><code>%%{init: {'theme': 'base',\n         }\n}%%\ngraph TD;\n\n  subgraph dnaTrace\n  A1([\"get_numpy_arrays() | Load Numpy arrays to dictionary indexed by number\"]) --&gt; A2([\"skimage.filters.gaussian() | Filter full image\"])\n  A2 -- For each image --&gt; A3([\"get_disordered_trace() | extracts mask\"])\n  A3 --&gt; A4([\"purge_obvious_crap() | Removes ites if len() &lt; 10 (i.e. small objects) \"])\n  A4 --&gt; A5([\"linear_or_circular on unordered traces() | linear or circular molecule\"])\n  A5 --&gt; A6([\"get_ordered_traces() | Reorders points in the array?\"])\n  A6 --&gt; A7([\"linear_or_circular() on ordered traces\"])\n  A7 --&gt; A8([\"get_fitted_traces()\"])\n  A8 --&gt; A9([\"get_splined_traces()\"])\n  A9 --&gt; A10([\"measure_contour_length()\"])\n  A10 --&gt; A11([\"measure_end_to_end_distance()\"])\n  A11 --&gt; A12([\"report_basic_stats()\"])\n  end\n\n  subgraph \"get_disordered_trace()\"\n  A3 --&gt; B1([\"ndimage.binary_dilation() | extracts mask\"])\n  B1 --&gt; B2([\"scipy.ndimage.gaussian_filter molecule()\"])\n  B2 --&gt; B3([\"getSkeleton()\"])\n  B3 --&gt; A4\n  end\n\n  subgraph \"getSkeleton()\"\n  B3 --&gt; C1([\"Skeletonize | to be replaced by get_skeleton()\"])\n  C1 --&gt; B3\n  end\n\n  style A1 fill:#648FFF,stroke:#000000\n  style A2 fill:#648FFF,stroke:#000000\n  style A3 fill:#648FFF,stroke:#000000\n  style A4 fill:#648FFF,stroke:#000000\n  style A5 fill:#648FFF,stroke:#000000\n  style A6 fill:#648FFF,stroke:#000000\n  style A7 fill:#648FFF,stroke:#000000\n  style A8 fill:#648FFF,stroke:#000000\n  style A9 fill:#648FFF,stroke:#000000\n  style A10 fill:#648FFF,stroke:#000000\n  style A11 fill:#648FFF,stroke:#000000\n  style A12 fill:#648FFF,stroke:#000000\n  style B1 fill:#DC267F,stroke:#000000\n  style B2 fill:#DC267F,stroke:#000000\n  style B3 fill:#DC267F,stroke:#000000\n  style C1 fill:#FE6100,stroke:#000000\n</code></pre>"}]}